---
title: A Multiverse Analysis of Interaction Effects
description: Running a multiverse moderation analysis over arbitrary data decisions and plotting the results
author: ''
date: '2020-08-16'
updated: "`r format(Sys.time(), '%B %d, %Y')`"
tocbot: true
slug: mutliverse
categories: []
tags:
  - R
  - multiverse
  - iteration
  - code
---

### Introduction

In recent years, there is a growing interest in multiverse analysis, a technique for compiling all possible datasets that could result from different data processing decisions. Once compiled, researchers can run their analysis of interest across all datasets in the mulitverse to see how sensitive their models are to the decisions made that produced the underlying data. In this post, I attempt my own multiverse analysis using simulated data.

Note that there are already many good places to learn more about the multiverse analysis, including papers, blog posts, and code examples. My intention is to understand the mechanics the technique without the aid of a pre-written package, deepen my own understanding, and to flesh out the different possible ways to use the technique and compile results.

#### Arbitrary vs. Non-Arbitrary Decisions

Processing raw data involves many steps. For example, the typical analysis involves cleaning, preparing, and creating analysis variables, among many other possible steps. Any specific set data processing choices eventually leads to an analysis-ready dataset. However, a slightly different set of choices will lead to a different analysis dataset. 

Data processing steps can be either arbitrary and non-arbitrary. Arbitrary decisions ar those that 1) not expected to influence results and 2) equally defensible/have reasonable justifications. For example, whether to remove outliers at a +/- 3 or 2.5 standard deviations could be a relatively arbitrary data processing decisions; neither cutoff is theoretically informed and both are equally defensible. Non-arbitrary choices should affect results. For example, controlling for a confound could be considered non-arbitrary on theoretical grounds or because doing so will aid interpretation (e.g., when the confound correlates with the outcome of interest). 

Multiverse analysis should be ran over all possible **arbitrary** decisions. This is important because the multiverse can quickly become very large and difficult to interpret. Thus, data analysts should take care to consider what data processing steps are arbitrary or not. Again, non-arbitrary decisions come from theory or empirical observations. 

#### Setup

To conduct my own multiverse analysis, I will be using a number of packages from the [tidyverse](www.tidyverse.org). Below are the specific packages I used for my setup:

```{r setup, message = F, warning= F}
# Load relevant libraries
library(tidyverse)
library(lmerTest)
library(broom.mixed)
library(tidymodels)
library(ggeffects)
library(showtext)

# Custom font for ggplot
font_add_google("Lato")
showtext_auto()

# Set the ggplot2 theme
theme_set(
  theme_light() +
    theme(
      text = element_text(family="Lato"),
      panel.grid = element_blank()
    )
)
```

#### Simulated Data

The raw data are randomly generated below. I modeled the variables based on an actual project I am working on. The research question is whether or not early life unpredictability (`iv_unp`) is associated with performance on a cognitive test with two versions, a standard (`dv_std`) and ecologically relevant (`dv_eco`) version. We hypothesize that unpredictability negatively impacts perforance on the standard version but enhances performance on the ecological version. To that end, I've made performance depend on `iv_unp` with some error.

Exclusion variables are also included in the data.

- `ex_sample`: The data (not these but those that I will be actually analzing in a real dataset) come from two samples. The first sample is smaller and considerably more difficult to run our protocol. The second sample is larger and was much easier to control how the protocol was executed. It is possible that our analysis will depend on wether or not we include the smaller subsample.
- `ex_csd`: socially desirable responding, which may have undue influence on our predictor. Children who experience adversity and do not want to report it may also score high on a measure of socially desirability.
- `ex_sped`: Some in our sample recieve special education. It is possible that some students may have cognitive impairments and shouldn't be analyzed with rest or the sample.
- `ex_att`: We included an a few trap questions in our assessment to detect individuals who may not be taking the study seriously.
- `ex_imp`: Our research assistants noted whether or not participants had trouble reading or seemed impaired somehow.

These variables will be used to constuct a multiverse of datasets.

```{r data}
# Set the seed for reproducibility
set.seed(12345)

# Create some data
sim_data <- 
  tibble(
    id          = 1:500,
    intercept   = rnorm(500, mean = 0, sd = 3),
    iv_unp      = rnorm(500, mean = 0, sd = 1),
    ex_sample   = rbinom(500, size = 1, prob = .2),
    ex_csd      = rnorm(500, mean = 0, sd = 1) + iv_unp * (.15) + rnorm(500, mean = 0, 1),
    ex_sped     = rbinom(500, size = 1, prob = .1),
    ex_att      = rbinom(500, size = 1, prob = .1),
    ex_imp      = rbinom(500, size = 1, prob = .05)
  ) %>% 
  mutate(
    intercept   = ifelse(ex_sped == 1, intercept - rnorm(1,.5,.25), intercept),
    intercept   = ifelse(ex_imp == 1, intercept - rnorm(1,.5,.25), intercept),
    intercept   = ifelse(ex_att == 1, intercept - rnorm(1,.25,.25), intercept),
    dv_std      = intercept + iv_unp * -(.2) + rnorm(500, mean = 0, 2),
    dv_eco      = intercept + iv_unp *  (.1) + rnorm(500, mean = 0, 2)
  )
```

```{r echo = F, message=F, warning=F}
head(sim_data) %>% 
  knitr::kable(digits = 2, format = 'html', table.attr = "class=\"uk-table uk-table-small uk-table-divider\"")
```

### The Arbitrary Data Decision Grid

The first step in conducting the multiverse is to construct a grid of filtering and/or processing steps. The function `expand_grid()` creates all possible combinations of these decisions. Our decisions are as follows:

- Include or exclude the smaller subsample
- Include or exclude people who failed attention checks
- Include or exclude participants with impairments
- Include or exclude special education status
- Include all scores, only scores > -3 SDs, or scores > -2.5 SDs
- Do nothing with social desirability, residualize `ex_csd` from `iv_unp`, or include `ex_csd` as a covariate

```{r decision-grid}
decision_grid <- 
  expand_grid(
    ex_sample    = c("ex_sample %in% c(0,1)", "ex_sample == 0"),
    ex_att       = c("ex_att %in% c(0,1)",    "ex_att == 0"),
    ex_imp       = c("ex_imp %in% c(0,1)",    "ex_imp == 0"),
    ex_sped      = c("ex_sped %in% c(0,1)",   "ex_sped == 0"),
    dv_std       = c("scale(dv_std) > -10", "scale(dv_std) > -3", "scale(dv_std) > -2.5"),
    dv_eco       = c("scale(dv_eco) > -10", "scale(dv_eco) > -3", "scale(dv_eco) > -2.5"),
    ex_csd       = c("0", "1", "2")
  )
```

The above grid contains `r nrow(decision_grid)` different data processing steps, which means our grid will produce a multiverse of `r nrow(decision_grid)` datasets. Note that each row contains character strings of the actual code that will be evaluated later to filter raw data. 

For plotting, I also created a grid key with nice names for each decision and nice names for the variables they refer to in the data.

```{r decision-key}
decision_grid_key <- 
  tribble(~variable,   ~variable_group, ~exp,                      ~name,
          "ex_sample", "Sample",        "ex_sample %in% c(0,1)", "Both Samples",
          "ex_sample", "Sample",        "ex_sample == 0",        "Sample 1",
          "ex_att",    "Attention",     "ex_att %in% c(0,1)",    "1 >= missed",
          "ex_att",    "Attention",     "ex_att == 0",           "None missed",
          "ex_imp",    "Impaired",      "ex_imp %in% c(0,1)",    "1 >= impairments",
          "ex_imp",    "Impaired",      "ex_imp == 0",           "No impairments",
          "ex_sped",   "Sp.Ed.",        "ex_sped %in% c(0,1)",   "Sp.Ed. included",
          "ex_sped",   "Sp.Ed.",        "ex_sped == 0",          "Sp.Ed. excluded",
          "dv_std",    "Std. Task",     "scale(dv_std) > -10",   "All scores",
          "dv_std",    "Std. Task",     "scale(dv_std) > -3",    "> -3 SD",
          "dv_std",    "Std. Task",     "scale(dv_std) > -2.5",  "> -2.5 SD",
          "dv_eco",    "Eco. Task",     "scale(dv_eco) > -10",   "All scores",
          "dv_eco",    "Eco. Task",     "scale(dv_eco) > -3",    "> -3 SD",
          "dv_eco",    "Eco. Task",     "scale(dv_eco) > -2.5",  "> -2.5 SD",
          "ex_csd",    "CSD",           "0",                     "Not included",
          "ex_csd",    "CSD",           "1",                     "Residualized",
          "ex_csd",    "CSD",           "2",                     "Covariate"
  )
```

```{r echo = F, message=F, warning=F}
decision_grid_key %>% 
  mutate(exp = paste0("`",exp,"`")) %>% 
  knitr::kable(digits = 2, format = 'html', table.attr = "class=\"uk-table uk-table-small uk-table-divider\"")
```

### Create the Multiverse

After creating the decision grid, we can place the filtering instructions inside a loop to iterate over the all possible decisions.  This creates a multiverse of `r nrow(decision_grid)` data sets. At the end of each iteration, I save a list of the data, sample size, and the specific decisions that produced the data. The result of this loop will be a large list of `r nrow(decision_grid)` elements, each of which are lists containing the above information. 

```{r}
# Loop through the multiverse grid and create datasets accordingly
multiverse_data <-
  decision_grid %>% 
  rownames_to_column("decision") %>% 
  split(.$decision) %>% 
  map(function(x){
    data <-
      sim_data %>% 
      filter(
        eval(parse(text = paste(x$ex_sample))), 
        eval(parse(text = paste(x$ex_att))), 
        eval(parse(text = paste(x$ex_imp))),
        eval(parse(text = paste(x$ex_sped))),
        eval(parse(text = paste(x$dv_std))),
        eval(parse(text = paste(x$dv_eco)))
      ) 
    
    decisions <- 
      x %>% 
      gather(variable, exp, -decision) %>% 
      left_join(decision_grid_key, by = c("variable" = "variable", "exp" = "exp"))
    
    list(
      n    = nrow(data),
      data = data,
      decisions = decisions
    )
    
  })
```

Here is an example of the first element of this list:

```{r }
multiverse_data[[1]]
```

#### Check Sample Sizes

We can also check the sample sizes of each universe in our multiverse:

```{r fig.showtext=T, fig.height=10}
mulitverse_sample_size <- 
  map_df(multiverse_data, function(x){
  # Grab the decisions flatten them out
  decisions <- x$decisions %>% 
    gather(key,value,-decision,-variable) %>% 
    unite(grid_vars, variable, key) %>% 
    spread(grid_vars, value)
  
  # Add the decisions to the model table
  bind_cols(n = x$n, decisions)
})

mulitverse_sample_size %>% 
  select(-ends_with("exp")) %>% 
  gather(variable, exclusion, -decision, -n) %>%
  mutate(variable = str_replace(variable, "_(name)$|_(variable_group)$", ".\\1\\2")) %>% 
  separate(variable, c("var","group"), sep = "\\.") %>% 
  spread(group, exclusion) %>% 
  arrange(decision, variable_group) %>% 
  ggplot() +
  geom_boxplot(aes(x = name, y = n), notch = T)  +
  scale_x_discrete("Exclusion Criteria") +
  scale_y_continuous("Sample Size (max = 500)\n") +
  ggtitle("Sample Sizes in the Multiverse") +
  facet_wrap(~variable_group, scales = "free", ncol = 2)
```

### Analyze the Multiverse 

We've generated our multiverse of datasets, now we need to perform our analysis. My strategy is to loop over my `multiverse_data` object. First, I extract the decisions that produced the data to know what we should do with `ex_csd` (i.e., create residualized scores, include it as a covariate, or do nothing). Then I restructure the data into long format so I can runa mixed model looking at the main effect of `iv_unp` (between subjects), main effect of `task_type` (standard or ecological version), and their interaction and estimating random intercepts for each participant.

At the end of each iteration, I compile another list with data, decisions that produced the data, whether or not `ex_csd` was residulized or included as a covariate (or niether), the mixed model object, a tidied table of the coefficients from the model, and table of predicted effects based on +/- 1 SD of `iv_unp` and `task_type` (standard or ecological) so we can visualize interactions. 

```{r warning=F,message=F,error=F}
# Loop through all the datasets in the multiverse and do the same analysis
multiverse_models <- 
  map(multiverse_data, function(x){
    # Get the expression that produced the data
    decisions <- x$decisions
    csd_decision <- x$decisions %>% filter(variable == "ex_csd") %>% pull(exp)
    
    # What to do with ex_csd
    nothing <- csd_decision == "0"
    residualize <- csd_decision == "1"
    covariate <-  csd_decision == "2"
    
    # restructure the data for mixed model
    data <- x$data %>%
      select(-intercept) %>% 
      mutate(iv_unp_z = scale(iv_unp) %>% as.numeric()) %>% 
      gather(task_type, score, -id, -iv_unp, -iv_unp_z, -starts_with("ex")) %>% 
      mutate(task_type = ifelse(task_type=="dv_std", -1, 1)) %>% 
      arrange(id, task_type)
    
    # Should ex_csd be partialed out of the IV?
    if(residualize){
      data_resids <- data %>% distinct(id,ex_csd,iv_unp_z)
      mod_residualized <- lm(iv_unp_z ~ ex_csd, data = data_resids)
      
      data_resids <- 
        augment(mod_residualized, data = data_resids) %>% 
        rename(iv_unp_resid = .resid) %>% 
        select(id, iv_unp_resid)
      
      data <- left_join(data, data_resids, by = "id") %>% 
        mutate(iv_unp_resid_z = scale(iv_unp_resid) %>% as.numeric())
      
      mod <- lmer(score ~ task_type*iv_unp_resid_z + (1|id), data = data)
      mod_effects <- ggpredict(mod, terms = c("iv_unp_resid_z [-1,1]", "task_type [-1,1]"))
    }
    
    # Should ex_csd be used as a covariate?
    if(covariate){
      mod <- lmer(score ~ task_type*iv_unp_z + ex_csd + (1|id), data = data)
      mod_effects <- ggpredict(mod, terms = c("iv_unp_z [-1,1]", "task_type [-1,1]"))
    }
    
    # Do not do anything with ex_csd
    if(nothing){
      mod <- lmer(score ~ task_type*iv_unp_z + (1|id), data = data)
      mod_effects <- ggpredict(mod, terms = c("iv_unp_z [-1,1]", "task_type [-1,1]"))
    }
    
    # Get the results and turn them into a data.frame
    mod_tidy <- 
      mod %>% 
      tidy() %>% 
      rename_all(~paste0("mod_",.))
    
    # Return a list of everything useful
    list(
      data         = data,
      decisions    = decisions,
      residualized = residualize,
      covariate    = covariate,
      mod          = mod,
      mod_tidy     = mod_tidy,
      mod_effects  = mod_effects
    )
  })
```

#### Multiverse Effect Sizes

With our multiverse of analysis results, we can extract the coefficients for plotting and interpretation. Here, I just loop through my multiverse and get the terms of interest (fixed main effects and interaction term).

```{r}
# Get the model estimates out of the giant list
multiverse_estimates <- 
  multiverse_models %>% 
  map_df(function(x){
    # Grab the decisions flatten them out
    decisions <- x$decisions %>% 
      gather(key,value,-decision,-variable) %>% 
      unite(grid_vars, variable, key) %>% 
      spread(grid_vars, value)
    
    # Add the decisions to the model table
    bind_cols(x$mod_tidy, n = x$n, decisions)
  })

# Only look at our main effects and interaction terms
multiverse_plot_data <- 
  multiverse_estimates %>% 
  filter(str_detect(mod_term,"^iv_unp_z$|^iv_unp_resid_z$|task")) %>% 
  mutate(
    term = str_remove(mod_term,"_resid"),
    term = factor(term, 
                  levels = c("iv_unp_z","task_type","task_type:iv_unp_z"), 
                  labels = c("Main Effect Unp","Main Effect Task","Interaction")),
    p_value = case_when(mod_p.value <= .05 ~ "p <= .05",
                        mod_p.value >  .05 ~ "p > .05"),
    p_value = factor(p_value, levels = c("p > .05","p <= .05"))
  ) %>% 
  group_by(term) %>% 
  mutate(multiverse_set = as.numeric(fct_reorder(decision, mod_estimate)))
```

### Displaying the Results

There is a lot of information derived from the multiverse analysis. An efficient way of looking at the results is to plot the effect size of each term from our model as a function of each decision, arrange from smallest to largest and (potentially) coloring the estimates by significance. Such a visualization typically has two panels. The first is the effect size curve and the second is a grid of specifications (i.e., decisions) that produced each effect.

Another way to evaluate the results is to create histograms of the p-values for each effect.

Finally, because I am primary interested in interactions, I want to plot the form of each interaction obtained. I can do that by plotting predicted estimates based on high and low unpredictability and task-type for every model.

#### Effect Size Curve

```{r ,fig.showtext=T, fig.height=2.5}
multiverse_effect_curve <- 
  multiverse_plot_data %>% 
  ggplot(aes(x = as.numeric(multiverse_set), y = mod_estimate, color = p_value)) +
  geom_point(size = .75, show.legend = F) +
  geom_ribbon(
    aes(x = as.numeric(multiverse_set), ymin = mod_estimate - mod_std.error, ymax = mod_estimate + mod_std.error, fill = p_value),
    alpha = .25, 
    inherit.aes = F, 
    show.legend = T
    ) +
  scale_y_continuous("Estimate") +
  scale_color_manual(values = c("gray","#f0506e")) +
  scale_fill_manual(values = c("gray","#f0506e")) +
  facet_wrap(~term) +
  theme(
    axis.text.x = element_blank(), 
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  )

multiverse_effect_curve
```

#### Specification Grid

```{r fig.showtext=T, fig.height=7.5}
multiverse_spec_grid <- 
  multiverse_plot_data %>% 
  select(-matches("exp$")) %>% 
  gather(variable, spec, matches("name|group$"), -starts_with("mod"), -decision, -multiverse_set) %>%
  mutate(variable = str_replace(variable, "_(name$)|_(variable_group$)",".\\1\\2")) %>% 
  separate(variable, c("variable","group"), sep = "\\.") %>% 
  spread(group,spec) %>% 
  ggplot(aes(x = multiverse_set, y = name, color = p_value)) +
  geom_point(size = .75, shape = 124, show.legend = F) +
  scale_y_discrete("Specification\n") +
  scale_x_continuous("\nMultiverse Dataset") +
  scale_color_manual(values = c("gray","#f0506e")) +
  facet_grid(variable_group~term, scales = "free_y") +
  theme(strip.background.x = element_blank(), strip.text.x = element_blank(), strip.placement = "outside")

multiverse_spec_grid
```

#### Creating the Full Multiverse Plot

```{r, fig.showtext = T, fig.height=7.5, message=F,warning=F}
cowplot::plot_grid(
  multiverse_effect_curve,
  multiverse_spec_grid,
  ncol = 1, 
  align = 'v', 
  axis = "lr",
  rel_heights = c(.25,.75)
)
```

#### The Multiverse of p-values

```{r fig.showtext = T, fig.height=3, warning=F, message=F}
multiverse_plot_data %>% 
  ggplot(aes(x = mod_p.value)) +
  geom_histogram(color = "black") +
  geom_vline(aes(xintercept = .05), color = "red", linetype = "dotted") +
  scale_x_continuous("\nMultiverse p-value") +
  scale_y_continuous("Count") +
  facet_wrap(~term, scales = "free_y")
```

#### Interaction plots

```{r fig.showtext = T, fig.height=3.5}
# Get the predicted points out of our giant list
multiverse_effects <- map_df(multiverse_models, function(x){
  decisions <- x$decisions %>% 
    gather(key,value,-decision,-variable) %>% 
    unite(grid_vars, variable, key) %>% 
    spread(grid_vars, value)
  
  bind_cols(x$mod_effects, n = x$n, decisions)
})

# Plot the interactions
multiverse_effects %>% 
  mutate(group = factor(group, levels = c(-1,1), labels = c("Standard Version","Ecological Version"))) %>% 
  ggplot(aes(x = x, y = predicted, group = decision)) +
  geom_line(alpha = .25,size = .5) +
  scale_x_continuous("\nEnvironmental Unpredictability") +
  scale_y_continuous("Performance") +
  facet_wrap(~group) 
```